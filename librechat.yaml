version: 1.2.8

cache: true
# Force Railway rebuild

memory:
  disabled: false
  validKeys:
    - "user_preferences"
    - "conversation_context"
    - "learned_facts"
    - "personal_information"
  tokenLimit: 3000
  personalize: true
  messageWindowSize: 8
  agent:
    provider: "openAI"
    model: "gpt-4o-mini"
    instructions: |
      Store memory using only the specified validKeys. For user_preferences: save
      explicitly stated preferences about communication style, topics of interest,
      or workflow preferences. For conversation_context: save important facts or
      ongoing projects mentioned. For learned_facts: save objective information
      about the user. For personal_information: save only what the user explicitly
      shares about themselves. Delete outdated or incorrect information promptly.
    model_parameters:
      temperature: 0.2
      max_tokens: 2000
      top_p: 0.8
      frequency_penalty: 0.1

interface:
  customWelcome: "Welcome to LibreChat! You can provide your own API keys in settings."
  fileSearch: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true

registration:
  socialLogins: []

endpoints:
  openAI:
    apiKey: "user_provided"
    models:
      default:
        - "gpt-4o"
        - "gpt-4o-mini"
        - "gpt-4-turbo"
        - "gpt-4"
        - "gpt-3.5-turbo"
      fetch: false
    titleConvo: true
    titleModel: "gpt-3.5-turbo"
    summarize: false
    summaryModel: "gpt-3.5-turbo"
    forcePrompt: false
    modelDisplayLabel: "OpenAI"

  anthropic:
    apiKey: "user_provided"
    models:
      default:
        - "claude-3-5-sonnet-20241022"
        - "claude-3-5-haiku-20241022"
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-3-haiku-20240307"
      fetch: false
    titleConvo: true
    titleModel: "claude-3-haiku-20240307"
    modelDisplayLabel: "Anthropic"

  google:
    apiKey: "user_provided"
    models:
      default:
        - "gemini-1.5-pro"
        - "gemini-1.5-flash"
        - "gemini-1.0-pro"
      fetch: false
    titleConvo: true
    titleModel: "gemini-1.5-flash"
    modelDisplayLabel: "Google"

  custom:
    - name: "groq"
      apiKey: "user_provided"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default:
          - "llama-3.3-70b-versatile"
          - "llama-3.2-90b-text-preview"
          - "llama-3.1-70b-versatile"
          - "llama-3.1-8b-instant"
          - "mixtral-8x7b-32768"
          - "gemma2-9b-it"
        fetch: false
      titleConvo: true
      titleModel: "llama-3.1-8b-instant"
      modelDisplayLabel: "Groq"

    - name: "OpenRouter"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default:
          - "meta-llama/llama-3.1-70b-instruct"
          - "anthropic/claude-3-5-sonnet"
          - "google/gemini-pro-1.5"
          - "openai/gpt-4-turbo-preview"
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/llama-3.1-70b-instruct"
      dropParams:
        - "stop"
      modelDisplayLabel: "OpenRouter"

    - name: "Mistral"
      apiKey: "user_provided"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default:
          - "mistral-large-latest"
          - "mistral-medium-latest"
          - "mistral-small-latest"
          - "mistral-embed"
        fetch: false
      titleConvo: true
      titleModel: "mistral-small-latest"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"
      modelDisplayLabel: "Mistral"

    - name: "Perplexity"
      apiKey: "user_provided"
      baseURL: "https://api.perplexity.ai"
      models:
        default:
          - "llama-3.1-sonar-large-128k-online"
          - "llama-3.1-sonar-small-128k-online"
          - "llama-3.1-sonar-large-128k-chat"
          - "llama-3.1-sonar-small-128k-chat"
        fetch: false
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      modelDisplayLabel: "Perplexity"

fileConfig:
  endpoints:
    default:
      fileLimit: 5
      fileSizeLimit: 10
      totalSizeLimit: 50
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/json"
