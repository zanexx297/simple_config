version: 1.2.8

cache: true
# Force Railway rebuild

memory:
  disabled: false
  validKeys:
    - "user_preferences"
    - "conversation_context"
    - "learned_facts"
    - "personal_information"
  tokenLimit: 3000
  personalize: true
  messageWindowSize: 8
  agent:
    provider: "openAI"
    model: "gpt-4o-mini"
    instructions: |
      Store memory using only the specified validKeys. For user_preferences: save
      explicitly stated preferences about communication style, topics of interest,
      or workflow preferences. For conversation_context: save important facts or
      ongoing projects mentioned. For learned_facts: save objective information
      about the user. For personal_information: save only what the user explicitly
      shares about themselves. Delete outdated or incorrect information promptly.
    model_parameters:
      temperature: 0.2
      max_tokens: 2000
      top_p: 0.8
      frequency_penalty: 0.1

interface:
  customWelcome: "Welcome to LibreChat! Add your API keys in settings to get started. ðŸš€"
  fileSearch: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  webSearch: true

registration:
  socialLogins: []

endpoints:
  openAI:
    apiKey: "user_provided"
    models:
      default:
        - "gpt-4o"
        - "gpt-4o-mini" 
        - "gpt-3.5-turbo"
      fetch: false
    titleConvo: true
    titleModel: "gpt-4o-mini"
    summarize: false
    summaryModel: "gpt-4o-mini"
    forcePrompt: false
    modelDisplayLabel: "OpenAI"

  anthropic:
    apiKey: "user_provided"
    models:
      default:
        - "claude-3-5-sonnet-20241022"
        - "claude-3-5-haiku-20241022"
        - "claude-3-opus-20240229"
      fetch: false
    titleConvo: true
    titleModel: "claude-3-5-haiku-20241022"
    modelDisplayLabel: "Anthropic"

  google:
    apiKey: "user_provided"
    models:
      default:
        - "gemini-1.5-pro"
        - "gemini-1.5-flash"
      fetch: false
    titleConvo: true
    titleModel: "gemini-1.5-flash"
    modelDisplayLabel: "Google"

  custom:
    - name: "groq"
      apiKey: "user_provided"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default:
          - "llama-3.3-70b-versatile"
          - "llama-3.1-8b-instant"
          - "mixtral-8x7b-32768"
        fetch: false
      titleConvo: true
      titleModel: "llama-3.1-8b-instant"
      modelDisplayLabel: "Groq (Fast)"

    - name: "OpenRouter"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default:
          - "meta-llama/llama-3.1-70b-instruct"
          - "anthropic/claude-3-5-sonnet"
          - "google/gemini-pro-1.5"
          - "openai/gpt-4-turbo-preview"
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/llama-3.1-70b-instruct"
      dropParams:
        - "stop"
      modelDisplayLabel: "OpenRouter"

    - name: "Mistral"
      apiKey: "user_provided"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default:
          - "mistral-large-latest"
          - "mistral-medium-latest"
          - "mistral-small-latest"
          - "mistral-embed"
        fetch: false
      titleConvo: true
      titleModel: "mistral-small-latest"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"
      modelDisplayLabel: "Mistral"

    - name: "Perplexity"
      apiKey: "user_provided"
      baseURL: "https://api.perplexity.ai"
      models:
        default:
          - "llama-3.1-sonar-large-128k-online"
          - "llama-3.1-sonar-small-128k-online"
          - "llama-3.1-sonar-large-128k-chat"
          - "llama-3.1-sonar-small-128k-chat"
        fetch: false
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      modelDisplayLabel: "Perplexity"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MCP SERVERS
mcpServers:
  clickup:
    command: "npx"
    args: ["-y", "@taazkareem/clickup-mcp-server@latest"]
    env:
      CLICKUP_API_KEY: "user_provided"
      CLICKUP_TEAM_ID: "user_provided"
      DOCUMENT_SUPPORT: "true"
    userProvide: true
    description: "ClickUp project management integration - requires personal API token and team ID"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FILE UPLOADS
fileConfig:
  endpoints:
    default:
      fileLimit: 10
      fileSizeLimit: 25
      totalSizeLimit: 100
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/json"
        - "text/csv"
        - "application/vnd.openxmlformats-officedocument.*"
        - "application/msword"
        - "text/markdown"
